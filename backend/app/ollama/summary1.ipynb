{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc2eb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from typing import List\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from transformers import LlamaTokenizer\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.embeddings import HuggingFaceEmbeddings  # Local embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc5b8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PDF Processing and Chunking with OCR\n",
    "class DataPrivacyProcessor:\n",
    "    def __init__(self):\n",
    "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "        \n",
    "    def extract_text_from_pdfs(self, pdf_paths: List[str]) -> List[str]:\n",
    "        all_chunks = []\n",
    "        for pdf_path in pdf_paths:\n",
    "            try:\n",
    "                with pdfplumber.open(pdf_path) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        text = page.extract_text()\n",
    "                        if text and len(text.strip()) > 10:\n",
    "                            chunks = [chunk.strip() for chunk in text.split('\\n\\n') if len(chunk) > 50]\n",
    "                            all_chunks.extend(chunks)\n",
    "                        else:\n",
    "                            img = page.to_image(resolution=300).original\n",
    "                            text = pytesseract.image_to_string(img)\n",
    "                            chunks = [chunk.strip() for chunk in text.split('\\n\\n') if len(chunk) > 50]\n",
    "                            all_chunks.extend(chunks)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {pdf_path}: {e}\")\n",
    "        return all_chunks\n",
    "\n",
    "    def vectorize_chunks(self, chunks: List[str]) -> np.ndarray:\n",
    "        try:\n",
    "            embeddings = self.embedder.encode(chunks, show_progress_bar=True)\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Vectorization failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3ae7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Retrieval System\n",
    "class PrivacyRetriever:\n",
    "    def __init__(self, embeddings: np.ndarray, chunks: List[str], embedder: SentenceTransformer):\n",
    "        self.chunks = chunks\n",
    "        self.embedder = embedder\n",
    "        self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(embeddings)\n",
    "        \n",
    "    def retrieve(self, query: str, top_k: int = 5) -> List[str]:\n",
    "        try:\n",
    "            query_embedding = self.embedder.encode([query])\n",
    "            distances, indices = self.index.search(query_embedding, top_k)\n",
    "            return [self.chunks[idx] for idx in indices[0]]\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Retrieval failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57e12aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RAG with LLaMA3:8B\n",
    "class PrivacyRAG:\n",
    "    def __init__(self, retriever: PrivacyRetriever, model_name='llama3:8b', max_tokens=4096):\n",
    "        self.retriever = retriever\n",
    "        self.model_name = model_name\n",
    "        self.max_tokens = max_tokens\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "        self.system_prompt = \"\"\"You are a data privacy expert. Using the provided context from data privacy laws and guidelines, answer the query accurately and concisely in formal legal language.\"\"\"\n",
    "    \n",
    "    def _truncate_context(self, context: str, query: str) -> str:\n",
    "        prompt_tokens = len(self.tokenizer.encode(self.system_prompt))\n",
    "        query_tokens = len(self.tokenizer.encode(query))\n",
    "        available_tokens = self.max_tokens - prompt_tokens - query_tokens - 100\n",
    "        context_tokens = self.tokenizer.encode(context)\n",
    "        if len(context_tokens) > available_tokens:\n",
    "            context_tokens = context_tokens[:available_tokens]\n",
    "            return self.tokenizer.decode(context_tokens)\n",
    "        return context\n",
    "    \n",
    "    def generate_response(self, query: str) -> str:\n",
    "        try:\n",
    "            context_chunks = self.retriever.retrieve(query)\n",
    "            context = \"\\n\\n\".join(context_chunks)\n",
    "            context = self._truncate_context(context, query)\n",
    "            full_prompt = f\"{self.system_prompt}\\n\\nContext:\\n{context}\\n\\nQuery:\\n{query}\"\n",
    "            response = ollama.generate(model=self.model_name, prompt=full_prompt)\n",
    "            return response['response']\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Generation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fdc06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. RAGAS Evaluation with Ollama\n",
    "def evaluate_rag(rag: PrivacyRAG, test_data: List[dict]) -> dict:\n",
    "    \"\"\"Evaluate RAG system using RAGAS with Ollama and local embeddings.\"\"\"\n",
    "    # Set up Ollama as the evaluation LLM\n",
    "    ollama_llm = OllamaLLM(model=\"llama3:8b\")\n",
    "    \n",
    "    # Set up local embeddings\n",
    "    local_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Prepare dataset\n",
    "    questions = [item['question'] for item in test_data]\n",
    "    ground_truths = [item['ground_truth'] for item in test_data]\n",
    "    contexts = []\n",
    "    answers = []\n",
    "    \n",
    "    for q in questions:\n",
    "        context_chunks = rag.retriever.retrieve(q)\n",
    "        contexts.append(context_chunks)\n",
    "        answers.append(rag.generate_response(q))\n",
    "    \n",
    "    dataset = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truth\": ground_truths\n",
    "    }\n",
    "    \n",
    "    # Evaluate with Ollama LLM and local embeddings\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "        llm=ollama_llm,\n",
    "        embeddings=local_embeddings  # Override default OpenAI embeddings\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4b65316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Based on the provided context from the updated IT Act, here are some of the penalties for data privacy violations:\n",
      "\n",
      "1. **Punishment for contravention**: Whoever contravenes any of the provisions of this Act shall be punishable with imprisonment for a term which may extend to three years or with fine which may extend to two lakh rupees or with both.\n",
      "2. **Punishment for abetment of offences**: Whoever abets any offence shall, if the act abetted is committed in consequence of the abetment, and no express provision is made by this Act for the punishment of such abetment, be punished with the punishment provided for the offence under this Act (Section 84B).\n",
      "3. **Punishment for failure to follow procedures**: Every Certifying Authority shall make use of hardware, software, and procedures that are secure from intrusion and misuse, provide a reasonable level of reliability in its services which are reasonably suited to the performance of intended functions, adhere to security procedures to ensure that the secrecy and privacy of electronic signatures are assured, and observe such other standards as may be specified by regulations (Section 30).\n",
      "4. **Punishment for unauthorized access**: The Controller or any person authorized by him shall exercise the like powers which are conferred on Income-tax authorities under Chapter XIII of the Income-tax Act, 1961, and shall exercise such powers subject to such limitations laid down under that Act (Section 29).\n",
      "\n",
      "These penalties apply to various forms of data privacy violations, including unauthorized access, failure to follow procedures for maintaining data security, and abetment of offences related to data privacy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    test_data = [\\n        {\\n            \"question\": \"What are the penalties for data privacy violations in the updated IT act?\",\\n            \"ground_truth\": \"Under DPDPA 2023, penalties can include fines up to INR 2 lakhs per instance.\"\\n        }\\n    ]\\n    evaluation_results = evaluate_rag(rag, test_data)\\n    print(\"RAGAS Results:\", evaluation_results)\\n    '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    processor = DataPrivacyProcessor()\n",
    "    pdf_paths = [\"it_act_2000_updated.pdf\"]\n",
    "    chunks = processor.extract_text_from_pdfs(pdf_paths)\n",
    "    embeddings = processor.vectorize_chunks(chunks)\n",
    "    \n",
    "    retriever = PrivacyRetriever(embeddings, chunks, processor.embedder)\n",
    "    rag = PrivacyRAG(retriever)\n",
    "    \n",
    "    query = \"What are the penalties for data privacy violations in the updated IT act?\"\n",
    "    response = rag.generate_response(query)\n",
    "    print(\"Response:\", response)\n",
    "    \n",
    "'''    test_data = [\n",
    "        {\n",
    "            \"question\": \"What are the penalties for data privacy violations in the updated IT act?\",\n",
    "            \"ground_truth\": \"Under DPDPA 2023, penalties can include fines up to INR 2 lakhs per instance.\"\n",
    "        }\n",
    "    ]\n",
    "    evaluation_results = evaluate_rag(rag, test_data)\n",
    "    print(\"RAGAS Results:\", evaluation_results)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671985d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
