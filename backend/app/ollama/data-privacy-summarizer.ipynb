{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2eb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from transformers import LlamaTokenizer\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.embeddings import HuggingFaceEmbeddings  # Local embeddings\n",
    "from typing import List, Dict, Union, Tuple\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5b8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PDF Processing and Chunking with OCR\n",
    "class DataPrivacyProcessor:\n",
    "    def __init__(self):\n",
    "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "        \n",
    "    def extract_text_from_pdfs(self, pdf_paths: List[str]) -> List[str]:\n",
    "        all_chunks = []\n",
    "        for pdf_path in pdf_paths:\n",
    "            try:\n",
    "                with pdfplumber.open(pdf_path) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        text = page.extract_text()\n",
    "                        if text and len(text.strip()) > 10:\n",
    "                            chunks = [chunk.strip() for chunk in text.split('\\n\\n') if len(chunk) > 50]\n",
    "                            all_chunks.extend(chunks)\n",
    "                        else:\n",
    "                            img = page.to_image(resolution=300).original\n",
    "                            text = pytesseract.image_to_string(img)\n",
    "                            chunks = [chunk.strip() for chunk in text.split('\\n\\n') if len(chunk) > 50]\n",
    "                            all_chunks.extend(chunks)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {pdf_path}: {e}\")\n",
    "        return all_chunks\n",
    "\n",
    "    def vectorize_chunks(self, chunks: List[str]) -> np.ndarray:\n",
    "        try:\n",
    "            embeddings = self.embedder.encode(chunks, show_progress_bar=True)\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Vectorization failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ae7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrivacyRetriever:\n",
    "    def __init__(self, embeddings: np.ndarray, chunks: List[str], embedder: SentenceTransformer):\n",
    "        self.chunks = chunks\n",
    "        self.embedder = embedder\n",
    "        # Normalize embeddings for cosine similarity\n",
    "        embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        self.index = faiss.IndexFlatIP(embeddings.shape[1])  # Inner product for cosine similarity\n",
    "        self.index.add(embeddings.astype(np.float32))  # FAISS requires float32\n",
    "        \n",
    "    def retrieve(self, query: str, top_k: int = 5, min_similarity: float = 0.5) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant chunks with similarity scores\n",
    "        \n",
    "        Args:\n",
    "            query: Search query string\n",
    "            top_k: Number of results to return\n",
    "            min_similarity: Minimum similarity score (0-1)\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples containing (chunk_text, similarity_score)\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If query encoding fails\n",
    "            RuntimeError: If retrieval fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Encode and normalize query\n",
    "            query_embedding = self.embedder.encode([query], show_progress_bar=False)\n",
    "            query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
    "            query_embedding = query_embedding.astype(np.float32)\n",
    "            \n",
    "            # Search index\n",
    "            similarities, indices = self.index.search(query_embedding, top_k)\n",
    "            \n",
    "            # Process results\n",
    "            results = []\n",
    "            for sim, idx in zip(similarities[0], indices[0]):\n",
    "                if sim >= min_similarity and 0 <= idx < len(self.chunks):\n",
    "                    results.append((self.chunks[idx], float(sim)))\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except ValueError as ve:\n",
    "            raise ValueError(f\"Query encoding failed: {ve}\")\n",
    "        except IndexError as ie:\n",
    "            raise RuntimeError(f\"FAISS index error: {ie}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Retrieval failed unexpectedly: {e}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e12aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RAG with LLaMA3:8B (Updated to handle tuples)\n",
    "class PrivacyRAG:\n",
    "    def __init__(self, retriever: PrivacyRetriever, model_name='llama3:8b', max_tokens=4096):\n",
    "        self.retriever = retriever\n",
    "        self.model_name = model_name\n",
    "        self.max_tokens = max_tokens\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "        self.system_prompt = \"\"\"You are a data privacy expert. Using the provided context from data privacy laws and guidelines, answer the query accurately and concisely in formal legal language.\"\"\"\n",
    "    \n",
    "    def _truncate_context(self, context: str, query: str) -> str:\n",
    "        prompt_tokens = len(self.tokenizer.encode(self.system_prompt))\n",
    "        query_tokens = len(self.tokenizer.encode(query))\n",
    "        available_tokens = self.max_tokens - prompt_tokens - query_tokens - 100\n",
    "        context_tokens = self.tokenizer.encode(context)\n",
    "        if len(context_tokens) > available_tokens:\n",
    "            context_tokens = context_tokens[:available_tokens]\n",
    "            return self.tokenizer.decode(context_tokens)\n",
    "        return context\n",
    "    \n",
    "    def generate_response(self, query: str) -> str:\n",
    "        try:\n",
    "            context_chunks_with_scores = self.retriever.retrieve(query)\n",
    "            # Extract only the chunks (first element of each tuple)\n",
    "            context_chunks = [chunk for chunk, _ in context_chunks_with_scores]\n",
    "            context = \"\\n\\n\".join(context_chunks)\n",
    "            context = self._truncate_context(context, query)\n",
    "            full_prompt = f\"{self.system_prompt}\\n\\nContext:\\n{context}\\n\\nQuery:\\n{query}\"\n",
    "            response = ollama.generate(model=self.model_name, prompt=full_prompt)\n",
    "            return response['response']\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Generation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fdc06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. RAGAS Evaluation with Ollama\n",
    "def evaluate_rag(rag: PrivacyRAG, test_data: List[dict]) -> dict:\n",
    "    \"\"\"Evaluate RAG system using RAGAS with Ollama and local embeddings.\"\"\"\n",
    "    # Set up Ollama as the evaluation LLM\n",
    "    ollama_llm = OllamaLLM(model=\"llama3:8b\")\n",
    "    \n",
    "    # Set up local embeddings\n",
    "    local_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Prepare dataset\n",
    "    questions = [item['question'] for item in test_data]\n",
    "    ground_truths = [item['ground_truth'] for item in test_data]\n",
    "    contexts = []\n",
    "    answers = []\n",
    "    \n",
    "    for q in questions:\n",
    "        context_chunks = rag.retriever.retrieve(q)\n",
    "        contexts.append(context_chunks)\n",
    "        answers.append(rag.generate_response(q))\n",
    "    \n",
    "    dataset = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truth\": ground_truths\n",
    "    }\n",
    "    \n",
    "    # Evaluate with Ollama LLM and local embeddings\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "        llm=ollama_llm,\n",
    "        embeddings=local_embeddings  # Override default OpenAI embeddings\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2c13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 6/6 [00:01<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Based on the provided context from data privacy laws and guidelines, here's how to plan an IS Audit as per the RBI guidelines:\n",
      "\n",
      "**Step 1: Define the Audit Universe**\n",
      " Identify the IT resources that are in scope for the audit based on the risk assessment process.\n",
      "\n",
      "**Step 2: Prepare the Audit Plan**\n",
      "Document the audit plan in a formal document, approved by the Audit Committee initially and during any subsequent major changes. The plan should include:\n",
      "\n",
      "* Internal Audit Subject (name of the audit subject)\n",
      "* Nature of Audit (compliance with legal, regulatory or standards, performance metrics assessment or security configuration testing)\n",
      "* Schedule (period of audit and its expected duration)\n",
      "* Scoped Systems (identified IT resources that are in scope based on the risk assessment process)\n",
      "* System Overview (details of system environment based on the risk assessment process)\n",
      "* Audit Details (details of risks and controls identified, based on the risk assessment process)\n",
      "* Nature and Extent of Tests (controls testing for effectiveness of design and implementation of controls, substantive testing for operating effectiveness of controls implemented)\n",
      "\n",
      "**Step 3: Adopt a Risk Assessment Methodology**\n",
      " Define, adopt, and follow a suitable risk assessment methodology that is in consonance with the focus on risks to be addressed as part of the overall Internal Audit Strategy.\n",
      "\n",
      "**Step 4: Identify IT Risks**\n",
      "Identify IT risks related to high-risk business areas identified by the Internal Audit for review during a year. This enables the IS Audit to provide assurance to management on the effectiveness of risk management and internal controls underlying high-risk business processes.\n",
      "\n",
      "**Step 5: Develop a Risk Profile and Draw up a Risk Matrix**\n",
      "Develop a risk profile and draw up a risk matrix taking into account inherent business risk and the effectiveness of the control system for monitoring the risk.\n",
      "\n",
      "**Step 6: Prepare an Annual Audit Plan**\n",
      "Prepare an annual audit plan, covering risks and prioritization, based on the level and direction of each risk. This plan should include:\n",
      "\n",
      "* Identification of appropriate personnel to undertake risk-based audit\n",
      "* Imparting them with relevant training\n",
      "* Addressing transitional and change management issues\n",
      "\n",
      "**Step 7: Implement the Audit Plan**\n",
      "Implement the audit plan, ensuring that all systems, domains, and processes, irrespective of their risk levels, are covered within a period of three years.\n",
      "\n",
      "**Additional Considerations**\n",
      "\n",
      "* Ensure that IT risks are considered in conjunction with information security-related guidelines issued by RBI.\n",
      "* Adopt a scoring system to evaluate business and control risks for business units, departments, and products.\n",
      "* Obtain Board or Audit Committee approval of risk assessments and annual Risk-based Audit Plans.\n",
      "\n",
      "By following these steps and considering the additional guidelines, you can plan an effective IS Audit as per the RBI guidelines.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    test_data = [\\n        {\\n            \"question\": \"What are the penalties for data privacy violations in the updated IT act?\",\\n            \"ground_truth\": \"Under DPDPA 2023, penalties can include fines up to INR 2 lakhs per instance.\"\\n        }\\n    ]\\n    evaluation_results = evaluate_rag(rag, test_data)\\n    print(\"RAGAS Results:\", evaluation_results)\\n    '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    processor = DataPrivacyProcessor()\n",
    "    pdf_paths = [\"./data-privacy-pdf/RBI-Guidelines.pdf\"]\n",
    "    chunks = processor.extract_text_from_pdfs(pdf_paths)\n",
    "    embeddings = processor.vectorize_chunks(chunks)\n",
    "    \n",
    "    retriever = PrivacyRetriever(embeddings, chunks, processor.embedder)\n",
    "    rag = PrivacyRAG(retriever)\n",
    "    \n",
    "    query = \"How to plan an IS Audit as per the RBI guidelines\"\n",
    "    response = rag.generate_response(query)\n",
    "    print(\"Response:\", response)\n",
    "    \n",
    "'''    test_data = [\n",
    "        {\n",
    "            \"question\": \"What are the penalties for data privacy violations in the updated IT act?\",\n",
    "            \"ground_truth\": \"Under DPDPA 2023, penalties can include fines up to INR 2 lakhs per instance.\"\n",
    "        }\n",
    "    ]\n",
    "    evaluation_results = evaluate_rag(rag, test_data)\n",
    "    print(\"RAGAS Results:\", evaluation_results)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
